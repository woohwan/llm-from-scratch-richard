{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e874451f",
   "metadata": {},
   "source": [
    "## 5장: 레이블이 없는 데이터를 활용한 사전 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef48bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 버전: 3.10.7\n",
      "numpy 버전: 1.26.4\n",
      "tiktoken 버전: 0.11.0\n",
      "torch 버전: 2.6.0\n",
      "tensorflow 버전: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\"]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1092d5",
   "metadata": {},
   "source": [
    "### 5.1.1 GPT를 사용해 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89655394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # 어휘 사전 크기\n",
    "    \"context_length\": 256, # 짧은 문맥 길이 (원본 길이: 1024)\n",
    "    \"emb_dim\": 768,        # 임베딩 차원\n",
    "    \"n_heads\": 12,         # 어텐션 헤드 개수\n",
    "    \"n_layers\": 12,        # 층 개수\n",
    "    \"drop_rate\": 0.1,      # 드롭아웃 비율\n",
    "    \"qkv_bias\": False      # 쿼리-키-값 생성시 편향 사용 여부\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efeab9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # 배치 차원을 삭제합니다.\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a513f6",
   "metadata": {},
   "source": [
    "### 5.1.2 텍스트 생성 손실 계산하기\n",
    "- 두 개의 훈련 샘플(행)에 대한 토큰 ID를 담고 있는 inputs 텐서가 있다고 가정해 보죠\n",
    "- inputs에 해당하는 targets은 모델이 생성해야 될 토큰 ID를 담고 있습니다.\n",
    "- 2장에서 데이터 로더를 구현할 때 설명했듯이 targets은 inputs에서 한 토큰씩 앞으로 이동한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091f6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72517e58",
   "metadata": {},
   "source": [
    "- inputs을 모델에 주입하면 각각 세 개의 토큰으로 구성된 두 개의 입력 샘플에 대한 로짓 벡터를 얻습니다.\n",
    "- 각각의 토큰은 어휘 사전 크기에 해당하는 50,257 차원의 벡터입니다.\n",
    "- 소프트맥스 함수를 적용하여 로짓 텐서를 확률 점수를 담고 있는 동일 차원의 텐서로 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b6dae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # 어휘 사전의 각 토큰에 대한 확률\n",
    "print(probas.shape) # 크기: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd922a4",
   "metadata": {},
   "source": [
    "- 이전 장에서 설명했듯이 argmax함수를 적용하여 확률 점수를 토큰 ID (인덱스)로 바꿀 수 있습니다.\n",
    "- 앞의 소프트맥스 함수는 각 토큰에 대해서 50,257차원의 벡터를 생성합니다. argmax 함수는 이 벡터에서 가장 높은 확률을 가진 위치를 반환합니다. 이것이 주어진 토큰에 대한 예측 토큰의 아이디입니다.\n",
    "- 배치에는 각각 세개의 토큰으로 구성된 두 개의 입력 샘플이 있으므로 2x3크기의 예측 토큰을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355dc421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 ID:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"토큰 ID:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f216a8",
   "metadata": {},
   "source": [
    "- 이 토큰을 디코딩하면 모델이 예측해야 할 토큰, 즉 타겟 토큰과 매우 다른 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed99e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플의 타깃:  effort moves you\n",
      "첫 번째 샘플의 출력:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"첫 번째 샘플의 출력: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ff9a8",
   "metadata": {},
   "source": [
    "- 타깃 인덱스에 해당하는 토큰 확률은 다음과 같습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc6ae3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3626, 6100,  345])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36e855",
   "metadata": {},
   "source": [
    "- 각 입력 샘플 토큰에 대한 정답 위치의 확률을 확인합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d7ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "텍스트 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"텍스트 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"텍스트 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f185762",
   "metadata": {},
   "source": [
    "- 확률이 1에 가까워지도록 이 값들을 최대화하는 것이 목표입니다.\n",
    "- 수학적 최적화에서는 확률 점수 자체를 최대화하는 것보다 확률 점수의 로그를 최대화하는 것이 쉽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84df8416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 토큰 확률의 로그를 계산합니다.\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f13034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad7a74",
   "metadata": {},
   "source": [
    "- 모델 가중치를 최적화하여 평균 로그 확률을 가능한 크게 만드는 것이 목표입니다.\n",
    "- 로그때문에 가장 큰 가능한 값은 0이며, 현재는 0에서부터 멀리 떨어져 있습니다.\n",
    "\n",
    "- 딥러닝에서는 평균 로그 확률을 최대화하는 것 대신에 음의 평균 로그 확률을 최소화하는 것이 일반적입니다. 이 예제의 경우 -10.7940를 최대화하여 0에 가깝게 만드는 것 대신에 10.7940을 최소화하여 0에 가깝게 만듭니다.\n",
    "- -10.7940의 음수 값, 즉, 10.7940을 딥러닝에서는 크로스 엔트로피 손실이라고 부릅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a79f91a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d649e",
   "metadata": {},
   "source": [
    "- cross_entropy 함수를 적용하기 전에 로짓과 타깃의 크기를 확인해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f476203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits size:  torch.Size([2, 3, 50257])\n",
      "target size:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 로짓의 크기는 (batch_size, num_tokens, vocab_size) 입니다.\n",
    "print(\"logits size: \", logits.shape)\n",
    "\n",
    "# 타깃의 크기의 (batch_size, num_tokens) 입니다.\n",
    "print(\"target size: \", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51b7fa",
   "metadata": {},
   "source": [
    "- 파이토치의 cross_entropy함수를 위해 배치 차원을 기준으로 합쳐서 텐서를 펼쳐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d858820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat logits:  torch.Size([6, 50257])\n",
      "flat targets:  torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# (batch, num_token, vocab_size) -> (total_tokens, vocab_size) vocab_size는 예측 벡터\n",
    "# 모든 샘플, 모든 토큰 위치에 대한 예측을 하나의 큰 목록으로 간주, 각 행은 vocab_size 크기의 예측 벡터 \n",
    "logits_flat = logits.flatten(0, 1) \n",
    "# targets는 (batch, num_tokens) 에는 vocab 내의 정답 인덱스\n",
    "targets_flat = targets.flatten() # total_tokens 갯수의 정답 인덱스\n",
    "\n",
    "print(\"flat logits: \", logits_flat.shape)\n",
    "print(\"flat targets: \", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f72490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d7f3a",
   "metadata": {},
   "source": [
    "### 5.1.3 훈련 세트와 검증 세트의 손실 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d50d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07091afe",
   "metadata": {},
   "source": [
    "- 다운로드한 텍스트를 확인하기 위해 처음과 끝에서 100개의 문자를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55251348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47bc2718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters:  20479\n",
      "tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"characters: \", total_characters)\n",
    "print(\"tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5667177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 훈련 세트 비율\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f351e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유효성 검사: context_length: 256\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "          \"`GPT_CONFG_124M['contxt_length']`를 낮추거나 \"\n",
    "          \"`train_ratio`를 증가시키세요\")\n",
    "    \n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "        \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
    "        \"`training_ratio`를 증가시키세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4c5a8",
   "metadata": {},
   "source": [
    "- 데이터가 올바르게 로드되었는 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "107be8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "검증 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 로더:\")\n",
    "for x , y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\n검증 데이터 로더:\")\n",
    "for x , y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22384555",
   "metadata": {},
   "source": [
    "- 토큰 크기가 예상 범위 안에 있는 지 추가로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d668953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 토큰 수: 4608\n",
      "검증 토큰 수: 512\n",
      "모든 토큰 수: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "    \n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "    \n",
    "print(\"훈련 토큰 수:\", train_tokens)\n",
    "print(\"검증 토큰 수:\", val_tokens)\n",
    "print(\"모든 토큰 수:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639afb0",
   "metadata": {},
   "source": [
    "- 주어진 배치에서 크로스 엔트로피 손실을 계산하는 유틸리티 함수를 작성합니다.\n",
    "- 또한 데이터 로더에서 사용자가 지정한 배치 개수 만큼 추출하여 손실을 계산하는 두 번째 유틸리티 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c15edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e148d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    toatl_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)  # num_batch가 지정되지 않으면 모든 배치를 순회합니다.\n",
    "    else:\n",
    "        # num_batches가 데이터 로더에 있는 배치 개수보다 크면\n",
    "        # 배치 횟수를 데이터 로더에 있는 총 배치 개수로 맟춥니다.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            toatl_loss += loss\n",
    "        else:\n",
    "            break\n",
    "    return toatl_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f09b2cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 손실: tensor(10.9876, device='cuda:0')\n",
      "검증 손실: tensor(10.9811, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"훈련 손실:\", train_loss)\n",
    "print(\"검증 손실:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f0150",
   "metadata": {},
   "source": [
    "## 5.2 LLM 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbd09719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # 손실과 지금까지 처리한 토큰 수를 추적하기 위해 리스트를 초기화합니다.\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    # 메인 훈련 루프를 시작합니다.\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()       # 모델을 훈련 모드로 설정합니다.\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()      # 이전 배치 반복에서 얻은 손실과 gradient를 초기화 합니다\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()             # 손실의 gradient를 계산합니다.\n",
    "            optimizer.step()           # loss gradient를 사용하여 모델 가중치를 update합니다.\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            \n",
    "            # 추가적인 평가 단계\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
    "        \n",
    "        # 각 에포크 후에 샘플 텍스트를 출력합니다.\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded= text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))      # 간결한 출력 포맷을 위해\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8e7d3",
   "metadata": {},
   "source": [
    "- 위에 정의한 훈련 함수로 LLM을 훈련해 보죠. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6675eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1 (Step 000000): 훈련 손실 9.817, 검증 손실 9.928\n",
      "에포크 1 (Step 000005): 훈련 손실 7.920, 검증 손실 8.336\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "에포크 2 (Step 000010): 훈련 손실 6.585, 검증 손실 7.044\n",
      "에포크 2 (Step 000015): 훈련 손실 5.985, 검증 손실 6.593\n",
      "Every effort moves you, the, and, the, the, the, the, the. \", the,,, the, and, the, of the, the, the,, the, the,, the, and,,,,, of\n",
      "에포크 3 (Step 000020): 훈련 손실 15.506, 검증 손실 15.669\n",
      "에포크 3 (Step 000025): 훈련 손실 5.595, 검증 손실 6.451\n",
      "Every effort moves you, and to the picture. Gis. G, and I had. I had, and I had. Gis, and, and. I had. I had to the his-- the \", and, and--. Gis, and\n",
      "에포크 4 (Step 000030): 훈련 손실 5.049, 검증 손실 6.346\n",
      "에포크 4 (Step 000035): 훈련 손실 4.606, 검증 손실 6.237\n",
      "Every effort moves you, and I had a--I was a--I had a of the a of the picture--I--and, I had to me, I had to the picture to me, I had been, I had a--and, I had a\n",
      "에포크 5 (Step 000040): 훈련 손실 4.110, 검증 손실 6.330\n",
      "Every effort moves you know it was his a little a--I was his pictures a little of his pictures: \"--I--I was a was.                       \n",
      "에포크 6 (Step 000045): 훈련 손실 3.581, 검증 손실 6.158\n",
      "에포크 6 (Step 000050): 훈련 손실 3.193, 검증 손실 6.117\n",
      "Every effort moves you know it was not that I felt.        \"I looked--I looked up, I had been to my dear, I had a little at my elbow and he had a little a little was, I was his\n",
      "에포크 7 (Step 000055): 훈련 손실 2.744, 검증 손실 6.132\n",
      "에포크 7 (Step 000060): 훈련 손실 2.088, 검증 손실 6.153\n",
      "Every effort moves you know,\" was one of the picture for a smile that, the picture.                                   \n",
      "에포크 8 (Step 000065): 훈련 손실 1.741, 검증 손실 6.189\n",
      "에포크 8 (Step 000070): 훈련 손실 1.361, 검증 손실 6.162\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.        \"Oh, and I said back his head to the donkey--and I had the donkey. \"There were days when I\n",
      "에포크 9 (Step 000075): 훈련 손실 1.117, 검증 손실 6.285\n",
      "에포크 9 (Step 000080): 훈련 손실 0.911, 검증 손실 6.304\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked at the and Mrs. \" back his head to look up at the honour being _mine_--because he's. \n",
      "에포크 10 (Step 000085): 훈련 손실 0.620, 검증 손실 6.400\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f33852c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    \n",
    "    # 에포크에 대한 훈련 손실과 검증 손실의 그래프를 그립니다.\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Train loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))      # only show integer lables on x-axis\n",
    "    \n",
    "    # 처리한 토큰 수에 대한 두 번째 x축을 만듭니다\n",
    "    ax2 = ax1.twiny()       # y축을 공유하는 두 번째 x축을 만듭니다\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)    # 눈금을 정렬하기 위해 투명한 그래프를 만듭니다\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "# plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "train_losses_cpu = [t.cpu().item() for t in train_losses]\n",
    "val_losses_cpu = [t.cpu().item() for t in val_losses]\n",
    "\n",
    "plot_losses(epochs_tensor.cpu(), tokens_seen, train_losses_cpu, val_losses_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d105a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
