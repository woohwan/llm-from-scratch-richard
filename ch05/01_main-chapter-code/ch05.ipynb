{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e874451f",
   "metadata": {},
   "source": [
    "## 5장: 레이블이 없는 데이터를 활용한 사전 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef48bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 버전: 3.10.7\n",
      "numpy 버전: 1.26.4\n",
      "tiktoken 버전: 0.11.0\n",
      "torch 버전: 2.6.0\n",
      "tensorflow 버전: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\"]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} 버전: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1092d5",
   "metadata": {},
   "source": [
    "### 5.1.1 GPT를 사용해 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89655394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # 어휘 사전 크기\n",
    "    \"context_length\": 256, # 짧은 문맥 길이 (원본 길이: 1024)\n",
    "    \"emb_dim\": 768,        # 임베딩 차원\n",
    "    \"n_heads\": 12,         # 어텐션 헤드 개수\n",
    "    \"n_layers\": 12,        # 층 개수\n",
    "    \"drop_rate\": 0.1,      # 드롭아웃 비율\n",
    "    \"qkv_bias\": False      # 쿼리-키-값 생성시 편향 사용 여부\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efeab9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # 배치 차원을 삭제합니다.\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a513f6",
   "metadata": {},
   "source": [
    "### 5.1.2 텍스트 생성 손실 계산하기\n",
    "- 두 개의 훈련 샘플(행)에 대한 토큰 ID를 담고 있는 inputs 텐서가 있다고 가정해 보죠\n",
    "- inputs에 해당하는 targets은 모델이 생성해야 될 토큰 ID를 담고 있습니다.\n",
    "- 2장에서 데이터 로더를 구현할 때 설명했듯이 targets은 inputs에서 한 토큰씩 앞으로 이동한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091f6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72517e58",
   "metadata": {},
   "source": [
    "- inputs을 모델에 주입하면 각각 세 개의 토큰으로 구성된 두 개의 입력 샘플에 대한 로짓 벡터를 얻습니다.\n",
    "- 각각의 토큰은 어휘 사전 크기에 해당하는 50,257 차원의 벡터입니다.\n",
    "- 소프트맥스 함수를 적용하여 로짓 텐서를 확률 점수를 담고 있는 동일 차원의 텐서로 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b6dae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # 어휘 사전의 각 토큰에 대한 확률\n",
    "print(probas.shape) # 크기: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd922a4",
   "metadata": {},
   "source": [
    "- 이전 장에서 설명했듯이 argmax함수를 적용하여 확률 점수를 토큰 ID (인덱스)로 바꿀 수 있습니다.\n",
    "- 앞의 소프트맥스 함수는 각 토큰에 대해서 50,257차원의 벡터를 생성합니다. argmax 함수는 이 벡터에서 가장 높은 확률을 가진 위치를 반환합니다. 이것이 주어진 토큰에 대한 예측 토큰의 아이디입니다.\n",
    "- 배치에는 각각 세개의 토큰으로 구성된 두 개의 입력 샘플이 있으므로 2x3크기의 예측 토큰을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355dc421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 ID:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"토큰 ID:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f216a8",
   "metadata": {},
   "source": [
    "- 이 토큰을 디코딩하면 모델이 예측해야 할 토큰, 즉 타겟 토큰과 매우 다른 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed99e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플의 타깃:  effort moves you\n",
      "첫 번째 샘플의 출력:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"첫 번째 샘플의 출력: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ff9a8",
   "metadata": {},
   "source": [
    "- 타깃 인덱스에 해당하는 토큰 확률은 다음과 같습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc6ae3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3626, 6100,  345])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36e855",
   "metadata": {},
   "source": [
    "- 각 입력 샘플 토큰에 대한 정답 위치의 확률을 확인합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d7ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "텍스트 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"텍스트 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"텍스트 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f185762",
   "metadata": {},
   "source": [
    "- 확률이 1에 가까워지도록 이 값들을 최대화하는 것이 목표입니다.\n",
    "- 수학적 최적화에서는 확률 점수 자체를 최대화하는 것보다 확률 점수의 로그를 최대화하는 것이 쉽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84df8416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 토큰 확률의 로그를 계산합니다.\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f13034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad7a74",
   "metadata": {},
   "source": [
    "- 모델 가중치를 최적화하여 평균 로그 확률을 가능한 크게 만드는 것이 목표입니다.\n",
    "- 로그때문에 가장 큰 가능한 값은 0이며, 현재는 0에서부터 멀리 떨어져 있습니다.\n",
    "\n",
    "- 딥러닝에서는 평균 로그 확률을 최대화하는 것 대신에 음의 평균 로그 확률을 최소화하는 것이 일반적입니다. 이 예제의 경우 -10.7940를 최대화하여 0에 가깝게 만드는 것 대신에 10.7940을 최소화하여 0에 가깝게 만듭니다.\n",
    "- -10.7940의 음수 값, 즉, 10.7940을 딥러닝에서는 크로스 엔트로피 손실이라고 부릅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a79f91a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d649e",
   "metadata": {},
   "source": [
    "- cross_entropy 함수를 적용하기 전에 로짓과 타깃의 크기를 확인해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f476203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits size:  torch.Size([2, 3, 50257])\n",
      "target size:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 로짓의 크기는 (batch_size, num_tokens, vocab_size) 입니다.\n",
    "print(\"logits size: \", logits.shape)\n",
    "\n",
    "# 타깃의 크기의 (batch_size, num_tokens) 입니다.\n",
    "print(\"target size: \", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51b7fa",
   "metadata": {},
   "source": [
    "- 파이토치의 cross_entropy함수를 위해 배치 차원을 기준으로 합쳐서 텐서를 펼쳐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d858820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat logits:  torch.Size([6, 50257])\n",
      "flat targets:  torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# (batch, num_token, vocab_size) -> (total_tokens, vocab_size) vocab_size는 예측 벡터\n",
    "# 모든 샘플, 모든 토큰 위치에 대한 예측을 하나의 큰 목록으로 간주, 각 행은 vocab_size 크기의 예측 벡터 \n",
    "logits_flat = logits.flatten(0, 1) \n",
    "# targets는 (batch, num_tokens) 에는 vocab 내의 정답 인덱스\n",
    "targets_flat = targets.flatten() # total_tokens 갯수의 정답 인덱스\n",
    "\n",
    "print(\"flat logits: \", logits_flat.shape)\n",
    "print(\"flat targets: \", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f72490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d7f3a",
   "metadata": {},
   "source": [
    "### 5.1.3 훈련 세트와 검증 세트의 손실 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d50d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07091afe",
   "metadata": {},
   "source": [
    "- 다운로드한 텍스트를 확인하기 위해 처음과 끝에서 100개의 문자를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55251348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47bc2718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters:  20479\n",
      "tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"characters: \", total_characters)\n",
    "print(\"tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5667177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 훈련 세트 비율\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f351e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유효성 검사: context_length: 256\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "          \"`GPT_CONFG_124M['contxt_length']`를 낮추거나 \"\n",
    "          \"`train_ratio`를 증가시키세요\")\n",
    "    \n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
    "        \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
    "        \"`training_ratio`를 증가시키세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4c5a8",
   "metadata": {},
   "source": [
    "- 데이터가 올바르게 로드되었는 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "107be8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "검증 데이터 로더:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 로더:\")\n",
    "for x , y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\n검증 데이터 로더:\")\n",
    "for x , y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22384555",
   "metadata": {},
   "source": [
    "- 토큰 크기가 예상 범위 안에 있는 지 추가로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d668953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 토큰 수: 4608\n",
      "검증 토큰 수: 512\n",
      "모든 토큰 수: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "    \n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "    \n",
    "print(\"훈련 토큰 수:\", train_tokens)\n",
    "print(\"검증 토큰 수:\", val_tokens)\n",
    "print(\"모든 토큰 수:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639afb0",
   "metadata": {},
   "source": [
    "- 주어진 배치에서 크로스 엔트로피 손실을 계산하는 유틸리티 함수를 작성합니다.\n",
    "- 또한 데이터 로더에서 사용자가 지정한 배치 개수 만큼 추출하여 손실을 계산하는 두 번째 유틸리티 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c15edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e148d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    toatl_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)  # num_batch가 지정되지 않으면 모든 배치를 순회합니다.\n",
    "    else:\n",
    "        # num_batches가 데이터 로더에 있는 배치 개수보다 크면\n",
    "        # 배치 횟수를 데이터 로더에 있는 총 배치 개수로 맟춥니다.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            toatl_loss += loss\n",
    "        else:\n",
    "            break\n",
    "    return toatl_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f09b2cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 손실: tensor(10.9876, device='cuda:0')\n",
      "검증 손실: tensor(10.9811, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"훈련 손실:\", train_loss)\n",
    "print(\"검증 손실:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f0150",
   "metadata": {},
   "source": [
    "## 5.2 LLM 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbd09719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # 손실과 지금까지 처리한 토큰 수를 추적하기 위해 리스트를 초기화합니다.\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    # 메인 훈련 루프를 시작합니다.\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()       # 모델을 훈련 모드로 설정합니다.\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()      # 이전 배치 반복에서 얻은 손실과 gradient를 초기화 합니다\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()             # 손실의 gradient를 계산합니다.\n",
    "            optimizer.step()           # loss gradient를 사용하여 모델 가중치를 update합니다.\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            \n",
    "            # 추가적인 평가 단계\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
    "        \n",
    "        # 각 에포크 후에 샘플 텍스트를 출력합니다.\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded= text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))      # 간결한 출력 포맷을 위해\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8e7d3",
   "metadata": {},
   "source": [
    "- 위에 정의한 훈련 함수로 LLM을 훈련해 보죠. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6675eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1 (Step 000000): 훈련 손실 9.817, 검증 손실 9.928\n",
      "에포크 1 (Step 000005): 훈련 손실 7.920, 검증 손실 8.336\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "에포크 2 (Step 000010): 훈련 손실 6.585, 검증 손실 7.044\n",
      "에포크 2 (Step 000015): 훈련 손실 5.985, 검증 손실 6.593\n",
      "Every effort moves you, the, and, the, the, the, the, the. \", the,,, the, and, the, of the, the, the,, the, the,, the, and,,,,, of\n",
      "에포크 3 (Step 000020): 훈련 손실 15.506, 검증 손실 15.669\n",
      "에포크 3 (Step 000025): 훈련 손실 5.595, 검증 손실 6.451\n",
      "Every effort moves you, and to the picture. Gis. G, and I had. I had, and I had. Gis, and, and. I had. I had to the his-- the \", and, and--. Gis, and\n",
      "에포크 4 (Step 000030): 훈련 손실 5.049, 검증 손실 6.346\n",
      "에포크 4 (Step 000035): 훈련 손실 4.606, 검증 손실 6.237\n",
      "Every effort moves you, and I had a--I was a--I had a of the a of the picture--I--and, I had to me, I had to the picture to me, I had been, I had a--and, I had a\n",
      "에포크 5 (Step 000040): 훈련 손실 4.110, 검증 손실 6.330\n",
      "Every effort moves you know it was his a little a--I was his pictures a little of his pictures: \"--I--I was a was.                       \n",
      "에포크 6 (Step 000045): 훈련 손실 3.581, 검증 손실 6.158\n",
      "에포크 6 (Step 000050): 훈련 손실 3.193, 검증 손실 6.117\n",
      "Every effort moves you know it was not that I felt.        \"I looked--I looked up, I had been to my dear, I had a little at my elbow and he had a little a little was, I was his\n",
      "에포크 7 (Step 000055): 훈련 손실 2.744, 검증 손실 6.132\n",
      "에포크 7 (Step 000060): 훈련 손실 2.088, 검증 손실 6.153\n",
      "Every effort moves you know,\" was one of the picture for a smile that, the picture.                                   \n",
      "에포크 8 (Step 000065): 훈련 손실 1.741, 검증 손실 6.189\n",
      "에포크 8 (Step 000070): 훈련 손실 1.361, 검증 손실 6.162\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.        \"Oh, and I said back his head to the donkey--and I had the donkey. \"There were days when I\n",
      "에포크 9 (Step 000075): 훈련 손실 1.117, 검증 손실 6.285\n",
      "에포크 9 (Step 000080): 훈련 손실 0.911, 검증 손실 6.304\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked at the and Mrs. \" back his head to look up at the honour being _mine_--because he's. \n",
      "에포크 10 (Step 000085): 훈련 손실 0.620, 검증 손실 6.400\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f33852c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    \n",
    "    # 에포크에 대한 훈련 손실과 검증 손실의 그래프를 그립니다.\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Train loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))      # only show integer lables on x-axis\n",
    "    \n",
    "    # 처리한 토큰 수에 대한 두 번째 x축을 만듭니다\n",
    "    ax2 = ax1.twiny()       # y축을 공유하는 두 번째 x축을 만듭니다\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)    # 눈금을 정렬하기 위해 투명한 그래프를 만듭니다\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "# plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "train_losses_cpu = [t.cpu().item() for t in train_losses]\n",
    "val_losses_cpu = [t.cpu().item() for t in val_losses]\n",
    "\n",
    "plot_losses(epochs_tensor.cpu(), tokens_seen, train_losses_cpu, val_losses_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89721c91",
   "metadata": {},
   "source": [
    "### 5.3 무작위성을 제어하기 위한 디코딩 전략\n",
    "- 위에서 구현한 GPT모델처럼 작은 LLM의 추론 비용은 비교적 저렴합니다. 따라서, 훈련에 GPU를 사용했더라도 추론에서는 GPU를 사용할 필요가 없습니다.\n",
    "- 이전 장에서 만든 generate_text_simple 함수를 사용해 한 번에 하나의 단어(또는 토큰)씩 새로운 텍스트를 생성할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05d105a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9e5ea",
   "metadata": {},
   "source": [
    "#### 5.3.1 온도 스케일링\n",
    "- 이전에는 torch.argmax 를 사용해 항상 가장 높은 확률은 가진 토큰을 다음 토큰으로 샘플링했습니다.\n",
    "- 다양성을 추가하기 위해 확률 분포에서 샘플링하도록 torch.multinormal(probs, num_samples=1)을 사용해 토큰을 샘플링할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9293bec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = { v: k for k, v in vocab.items()}\n",
    "\n",
    "# 입력이 \"every effort moves you\"이고,\n",
    "# LLM이 다음 토큰을 위해 아래와 같은 로짓을 반환했다고 가정해 보죠\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 생성될 토큰은 다음과 같습니다\n",
    "print(inverse_vocab[next_token_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd7e95f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c19b639",
   "metadata": {},
   "source": [
    "- torch.argmax 로 가장 가능성이 높은 토큰을 결정하는 대신에 torch.multinomial(probas, mum_samples=1) 를 사용해 소프트맥스 분포에서\n",
    "샘플링하여 가장 가능성이 높은 토큰을 결정할 수 있습니다.\n",
    "- 설명을 위해 원래 소프트맥스 분포에서 1,000번 토큰을 샘플링해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df8386ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [ torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4793fe",
   "metadata": {},
   "source": [
    "- 온도 스케일링으로 분포와 선택과정을 조절할 수 있습니다.\n",
    "- \"온도 스케일링\"은 로짓을 0보다 큰 숫자로 나누는 것을 의미합니다.\n",
    "- 1보다 큰 온도는 소프트맥스 함수를 적용한 후에 더 균등한 토큰 확률 분포를 만듭니다.\n",
    "- 1보다 작은 온도는 소프트맥스 함수를 적용한 후에 더 결정론적인 분포(더 날카롭거나 뾰족한 분포)를 만듭니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c99d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# 온도 값\n",
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "# scale을 조정한 확률 계산\n",
    "scaled_probas = [ softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e232c638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i*bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "    \n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "799a4db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03]), tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
      "        2.9718e-38, 9.0133e-03, 2.8514e-22]), tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a21fbf6",
   "metadata": {},
   "source": [
    "#### 5.3.2 탑-k 샘플링\n",
    "- 높은 온도를 사용하여 출력의 다양성을 증가시키면서 말이 안되는 문장이 생성될 가능성을 낮추기 위해 가장 가능성 있는 상위 k개 \n",
    "토큰으로 샘플링될 토큰을 제한할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3dcbfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탑-k 로짓: tensor([6.7500, 6.2800, 4.5100])\n",
      "탑-k 위치: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"탑-k 로짓:\", top_logits)\n",
    "print(\"탑-k 위치:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7599b1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9738556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topK_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topK_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b21d7e",
   "metadata": {},
   "source": [
    "#### 5.3.3 텍스트 생성 함수 수정하기\n",
    "- 이전 두 개의 절에서 온도 스케일링과 탑-k 샘플링을 소개했습니다.\n",
    "- 두 개념을 사용해 앞서 LLM으로 텍스트를 생성할 때 사용한 generate_sample 함수를 수정해 새로운 generate 함수를 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "464e119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # for 루프는 이전과 동일합니다. 로짓을 받아 마지막 타임 스텝만 사용합니다.\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 탑-k 샘플링으로 로짓을 필터링합니다.\n",
    "        if top_k is not None:\n",
    "            # 탑-k 값만 유지합니다.\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # 온도 스케일링을 적용합니다.\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # 소프트맥스 함수를 적용하여 확률을 얻습니다.\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # 분포에서 샘플링합니다.\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # 온도 스케일링을 사용하지 않는 경우 이전처럼 그리디 샘플링을 사용해 다음 토큰을 선택합니다.\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # eos_id가 지정되어 있고 EoS 토큰을 만나면 생성을 중단합니다.\n",
    "            break\n",
    "\n",
    "        # 이전과 동일하게 샘플링된 인덱스를 현재 시퀀스 뒤에 추가합니다.\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b9b0173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you know began to happen a little wild--I was such not to see her\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedfac8",
   "metadata": {},
   "source": [
    "### 5.4 파이토치 모델 로드하고 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3d3c9",
   "metadata": {},
   "source": [
    "- 파이토치에서는 torch.save 함수를 .state_dict() 메서드 결과에 적용해 소위 state_dict인 모델 가중치를 저장하는 것이 권장됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "364d8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e51ea6",
   "metadata": {},
   "source": [
    "- 그 다음 모델 가중치를 새로운 GPTModel 클래스 인스턴스에 로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9c61e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c804f",
   "metadata": {},
   "source": [
    "- 일반적인 SGD 대신 Adam이나 AdamW와 같이 적응형 옵티마이저로 LLM을 훈련하는 것이 일반적\n",
    "- 이런 적응형 옵티마이저는 모델 가중치마다 추가적인 파라미터를 저장합니다. 나중에 사전 훈련을 계속하려면 이 파라미터도 저장하는 것이 맞습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65727255",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b46ee73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda524e5",
   "metadata": {},
   "source": [
    "### 5.5 오픈AI에서 사전 훈련된 가중치 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff3762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 07:41:34.057766: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 07:41:34.513705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 07:41:35.750693: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 72.2kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.27MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 84.4kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [04:07<00:00, 2.01MiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 4.94MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 727kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 708kiB/s] \n"
     ]
    }
   ],
   "source": [
    "# settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612eef28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "# print(\"설정:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파라미터 딕셔너리 키: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "# print(\"파라미터 딕셔너리 키:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf73df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "토큰 임베딩 가중치 텐서의 차원: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "# print(params[\"wte\"])\n",
    "# print(\"토큰 임베딩 가중치 텐서의 차원:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9841ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리로 모델 설정을 저장합니다.\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# 기본 설정을 특정 값으로 업데이트합니다.\n",
    "model_name = \"gpt2-small (124M)\"  # 모델 이름\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85520ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"크기가 다릅니다. left: {left.shape}, right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2e403dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "252cf8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 텍스트:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503bbe64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
